Implementing only with Numpy:
The coursework is about implementing a k-nearest neighbors (k-NN) classifier and using it to classify two datasets: the IRIS PLANT and the PIMA INDIANS DIABETES. The goal was to report the percentage of correct classification as a function of the number of nearest neighbors, using cross-validation to obtain the results.

Additionally, for the PIMA INDIANS DIABETES DATABASE, estimations od the probability density functions (PDFs) using different assumptions were performed and measures of the goodness of the fits were calculated. Furthermore, a Bayes classifier was implemented, and its performance with the k-NN classifier was compared.

Finally, the perceptron algorithm was used to examine whether the data of each class (of the IRIS PLANT DATABASE) is linearly separable from the data of the combined remaining classes.
